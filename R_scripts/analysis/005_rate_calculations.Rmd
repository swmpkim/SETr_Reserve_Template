---
title: "SET Rate Calculations"
date: "`r Sys.Date()`"
output: word_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

Everything in this report currently uses ALL reported data values. Quality flags were ignored, which may lead to differences in final numbers once we deal with QA/QC issues.  

Also, be aware that linear models are not appropriate for calculating rates of change at all sites. Use discretion about these results.  

__Additional Note:__ We're moving away from the description below and using Linear Mixed Models to calculate SET rates of change. I'm keeping all the stuff below for now because of the formatting, graphics, etc.; need to change it over but want you all to see my ideas about presenting the information.  

Rates of change were calculated first for each pin using a linear model of pin_height vs. date. Rates were converted from mm/day to mm/year by multiplying by 365.25 (to account for leap years). So linear models result in 36 rates of change per SET.  

Rates from the 36 pins were averaged to one rate per SET. This is the rate reported here.    

Note that, provided no data are missing, this rate is the same as the rate generated by averaging all the 9 pins per arm and then averaging the 4 arms' rates together. Variance is, however, different.  


# Setup  

The following R packages are required to generate this report:  

```{r load_libraries, echo = TRUE}
library(knitr)
library(readr)
library(readxl)
library(janitor)
library(dplyr)
library(tidyr)
library(ggplot2)
library(nlme)
library(broom)
library(here)
source(here::here('R_scripts', '000_functions.R'))
```


## Read in data and metadata  

This reads in the long dataset, converted from other formats by earlier scripts. It also converts pin heights to mm if they weren't already in those units.    

```{r read_data, warning = TRUE}
################################################################################
# get the data in
################################################################################

# find the folder with processed data
path <- here::here('data', 'processed')

# in that folder, find the name of the file(s) that ends with 'set.csv'
filelist <- grep('set_QC.csv$', dir(path), value = TRUE)



# generate warnings if the folder is empty; if there are multiple matching files, select the first one
if (length(filelist) == 0) stop("There are no files of the correct name/format (---set_QC.csv) in your processed data folder.")

if (length(filelist) > 1) {
    warning("There is more than one file of the correct format (---set_QC.csv) in your data folder. The first file alphabetically will be used.")
    filelist <- filelist[1]
}



# generate the full path to the file; read it in and get pin heights to mm
filename <- paste0(path, "/", filelist)
dat <- read_csv(filename)
dat <- height_to_mm(dat)



# if the date column is datetime, posixct, or posixlt, change it to Date
if (sum(class(dat$date) %in% c("datetime", "POSIXct", "POSIXlt")) > 0)
    dat$date <- as.Date(dat$date)
    
###############################################################################

# get rid of any placeholders; make sure set_id is a factor  
dat <- dat %>%
    filter(!is.na(date),
           !is.na(pin_number)) %>%
    mutate(set_id = as.factor(set_id))
```


### Sanity checks  

This analysis was run on `r filelist[1]` on `r Sys.Date()`.


```{r read_metadata, warning = TRUE}
################################################################################
# get the metadata in
################################################################################

# find the folder with metadata
path <- here::here('metadata')

# in that folder, find the name of the file(s) that ends with 'setm.csv'
filelist <- grep('set_metadata.xls', dir(path), value = TRUE)

# generate warnings if the folder is empty; if there are multiple matching files, select the first one
if (length(filelist) == 0) stop("There are no files of the correct name/format (---set_metadata.xls or .xlsx) in your metadata folder.")

if (length(filelist) > 1) {
    warning("There is more than one file of the correct format (---set_metadata.xls or .xlsx) in your metadata folder. The first file alphabetically will be used.")
    filelist <- filelist[1]
}

# generate the full path to the file; read it in, clean the names, get rid of empty rows and columns
filename <- paste0(path, "/", filelist)
mdat <- read_excel(filename) %>%
    clean_names() %>%
    janitor::remove_empty(which = c("rows", "cols"))

###############################################################################

```


Make sure the same SET IDs exist in both the data and metadata file.   

```{r verify_setid, warning = TRUE}
# first pull out set_id from both data frames
data_setid <- unique(as.character(dat$set_id))
metadata_setid <- unique(mdat$unique_set_id)

# find set_ids that are in the data, but not in the metadata
dat_not_m <- setdiff(data_setid, metadata_setid)
# find set_ids that are in the metadata, but not in the data
m_not_dat <- setdiff(metadata_setid, data_setid)

if (length(dat_not_m) > 0) {
    toprint <- paste(dat_not_m, collapse = ", ")
    warning(paste0("The following SET IDs exist in your data, but not in your metadata: ", toprint))
}

if (length(m_not_dat) > 0) {
    toprint <- paste(m_not_dat, collapse = ", ")
    warning(paste0("The following SET IDs exist in your metadata, but not in your data: ", toprint))
}

if (length(dat_not_m) + length(m_not_dat) == 0) {
    print("SET IDs match in your data and metadata files.")
}

# cleanup
rm(dat_not_m, m_not_dat, metadata_setid, data_setid, filelist, filename, path)
```


Read in general sea-level rates sheet and pull out the rate that matches the reserve.  

```{r read_slr}
slr_path <- here::here('metadata')
slr_file <- paste0(slr_path, "/slr_rates.csv")
slr_rates <- read_csv(slr_file) %>%
    clean_names() %>%
    janitor::remove_empty(which = c("rows", "cols"))
```

Pull out the information relevant to the current reserve. Assign relevant values to objects and print out the table with information about the site.   

```{r verify_slr, warning = TRUE}
res_to_match <- unique(dat$reserve)

if (res_to_match %in% unique(slr_rates$reserve)) {
    slr_res <- slr_rates %>%
        filter(reserve == res_to_match) %>%
        select(-link)
    slr <- slr_res$slr_rate_mm_yr
    slr_ci <- slr_res$x95_percent_ci
} else {warning("This reserve does not have an entry in the sea level rise rates file. Please check metadata/slr_rates.csv and make sure your reserve is present.")}
```



# Background information  

Necessary context; pull from metadata file    

## Reserve-level  

Bullet-point list, probably, to include:    

+  geomorphic setting  
+  tidal range  
+  Local rate of sea level change is **`r slr`** +/- **`r slr_ci`** mm/yr.  
+  This rate is reported by `r slr_res$nearest_nwlon_station`, NWLON station number `r as.character(slr_res$nwlon_station_number)` based on data from *`r slr_res$data_start`* to *`r slr_res$data_end`*.
  

## SET-level  

This should probably be a table (or series of tables) with info pulled out of metadata spreadsheet.

```{r}
mdat %>%
    select(unique_set_id, set_type, latitude_dec_deg, longitude_dec_deg, co_dominant_species1, co_dominant_species2, co_dominant_species3) %>%
    knitr::kable(align = "c", col.names = c("SET ID", "Type", "Lat", "Long", "Main Veg 1", "Main Veg 2", "Main Veg 3"))
```


+  NAVD88 elevation (and year determined)  
+  Years of data collection  
+  Distance from closest water body 


***

# Rate Calculations  

## Pin level  

Calculate a linear rate of change for each pin at each SET.  

**Linear regression for each pin.** Keeping errors and confidence intervals in here just so we can describe the linear regression model should it ever be necessary. But really we'll only be working with *rate_mm.yr* from here on out.  

Note that the Confidence Intervals here were generated by the lm() function.  

These values are not shown but can be if people want them.  


```{r rates_pins, rows.print = 9}
# generate linear model for each pin
models <- dat %>%
    group_by(reserve, set_id, arm_position, pin_number) %>%
    do(mod = lm(pin_height ~ date, data = .))  


# pull out coefficients of interest:
# intercept, slope, p-value, 95% confidence bounds
modelcoef <- tidy(models, mod, conf.int=TRUE, conf.level=0.95) 


# get rid of intercept row,
# calculate mm/yr for all the terms,
# get rid of the mm/day stuff
# p-value and statistic are rounded
rates_elev_pins <- modelcoef %>%
    filter(term == "date") %>%
    mutate(rate_mm.yr = estimate*365.25,
           se_mm.yr = std.error*365.25,
           CIlow_mm.yr = conf.low*365.25,
           CIhigh_mm.yr = conf.high*365.25,
           p_value = round(p.value, 4),
           statistic = round(statistic, 3)) %>%
    select(reserve, set_id, arm_position, pin_number, rate_mm.yr, se_mm.yr, CIlow_mm.yr, CIhigh_mm.yr, statistic, p_value)


# calculate r^2, adjusted r^2, p values, and other model diagnostics
modelsummary_pins <- glance(models, mod) 
```


***


## SET level: All rates  

Average of the 36 pins' rates.  

95% Confidence Intervals are calculated as:  
`mean +/- [1.96 * standard error]`  

<br>

```{r rates_sets}
rates_elev_set <- rates_elev_pins %>%
    group_by(reserve, set_id) %>%
    summarize(rate_mm.yr_set = mean(rate_mm.yr, na.rm = TRUE),
              sd_mm.yr = sd(rate_mm.yr, na.rm = TRUE),
              se_mm.yr = sd_mm.yr/sqrt(n())) %>%
    mutate(CI95_low = rate_mm.yr_set - 1.96*se_mm.yr,
           CI95_high = rate_mm.yr_set + 1.96*se_mm.yr) %>%
    ungroup()

knitr::kable(rates_elev_set,
             caption = "Rate of Elevation Change by SET", 
             col.names = c("Reserve", "SET ID", "Rate (mm/yr)", "stdev", "sterr", "95% CI lower bound", "95% CI upper bound"),
             digits = 3,
             align = 'c')
```

***


# Sea Level Rise Comparisons  

The long-term local rate of sea level rise is **`r slr` +/- `r slr_ci` mm/yr** .

The following tables break the SETs into groups where the rate of SET elevation change is *lower than* / *higher than* / *not different from* this SLR rate.  

95% Confidence Intervals are calculated as:  
`mean +/- [1.96 * standard error]`  

<br>

***

<br>

```{r slr_comp_lower}
rates_elev_set %>%
    filter(CI95_high < slr) %>%
    select(reserve, set_id, rate_mm.yr_set, CI95_low, CI95_high) %>%
    knitr::kable(caption = "SETs where elevation change is lower than SLR",
                 col.names = c("Reserve", "SET ID", "Rate (mm/yr)", "95% CI lower bound", "95% CI upper bound"),
                 digits = 3,
                 align = 'c')
```

<br>

***

<br>

```{r slr_comp_higher}
rates_elev_set %>%
    filter(CI95_low > slr) %>%
    select(reserve, set_id, rate_mm.yr_set, CI95_low, CI95_high) %>%
    knitr::kable(caption = "SETs where elevation change is higher than SLR",
                 col.names = c("Reserve", "SET ID", "Rate (mm/yr)", "95% CI lower bound", "95% CI upper bound"),
                 digits = 3,
                 align = 'c')
```

<br>

***

<br>

```{r slr_comp_same}
rates_elev_set %>%
    filter(CI95_low < slr & CI95_high > slr) %>%
    select(reserve, set_id, rate_mm.yr_set, CI95_low, CI95_high) %>%
    knitr::kable(caption = "SETs where the 95% CI for elevation change rate includes SLR",
                 col.names = c("Reserve", "SET ID", "Rate (mm/yr)", "95% CI lower bound", "95% CI upper bound"),
                 digits = 3,
                 align = 'c')
```

***  

# Graph  

for a sanity check of the above rates  

Linear regression is NOT appropriate for all sites; interpret this with caution

```{r plot_all_pins, fig.width = 7, fig.height = 9}
ggplot(dat, aes(x = date, y = pin_height)) +
    geom_point(aes(col = arm_position), alpha = 0.6) +
    facet_wrap(~set_id, ncol = 4, scales = "free_y") +
    geom_smooth(method = 'lm', se = FALSE, size = 2, col = "black") +
    labs(title = "Pin readings by date", subtitle = "with linear regression through all pins", x = "Date", y = "Pin Height (mm)") +
    scale_fill_discrete(name = 'Arm Position') +
    theme_bw() +
    theme(legend.position = 'bottom')
```

# Another graph  

To visualize confidence intervals; because calculated SLR rate also has a standard error  

```{r plot_slr_ci, fig.width = 7, fig.height = 6}
ggplot() +
    geom_blank(data = rates_elev_set, aes(x = set_id, y = rate_mm.yr_set)) +
    geom_ribbon(aes(x = 0:(nrow(rates_elev_set)+1), ymin = slr-slr_ci, ymax = slr+slr_ci), fill = "navyblue", alpha = 0.1) +
    geom_hline(aes(yintercept = slr), col = "navyblue", size = 1, alpha = 0.9) +
    geom_hline(aes(yintercept = 0), col = "gray70") +
    geom_errorbar(data = rates_elev_set, aes(x = set_id, ymin = CI95_low, ymax = CI95_high), col = "gray55", size = 1) +
    geom_point(data = rates_elev_set, aes(x = set_id, y = rate_mm.yr_set), size = 3, col = "red3") +
    theme_classic() + 
    labs(title = "Elevation Change, 95% Confidence Intervals", subtitle = paste0("Local SLR in blue: ", slr, " +/- ", slr_ci, " mm/yr"), x = "SET", y = "Rate of change (mm/yr)") +
    coord_flip()
```


***
***

# Linear Mixed Models  

Some experimentation with linear mixed models for rate. From Cahoon et al. 2018:

Linear mixed models (LMMs, Zuur et al. 2009) were chosen
to analyze the surface elevation data. LMMs are ideal for
analyzing the nested longitudinal data that is produced by
the SET device. Rather than averaging the pin heights from
each SET prior to analysis, the measurements from each pin
are used as separate replicates. This preserves the variation
found within each SET and also maximizes statistical power.
Effects which are specific to each SET, direction within each
SET, and pin within each direction are treated as random
effects, which account for the lack of independence among
pins on the same SET. Analysis was performed using
mixed-effect models in the nlme package (Pinheiro et al.
2016) in R version 3.3.2 (R Core Team 2016).
Data from each of the five sites were analyzed separately.
Pin height (m, NAVD88) served as the response variable, and
the fixed effects were the number of days since the initial
reading was taken. To account for a potential reduction of
independence among pins on the same SET, the model included
a random slope and intercept for each pin, nested in the SET
position on the benchmark (typically, four positions were read
during each sampling event), nested in the SET. This model
was first fit using maximum likelihood. It was then compared
to a model with identical random effects but an intercept-only
fixed effect using the corrected form of Akaikeâ€™s information
criterion (AICc, Akaike 1974, Burnham and Anderson 2004).
If the intercept-only model was superior, this indicated that
there is no trend in elevation over time. The model including
a trend through time was then refit using restricted maximum
likelihood to estimate the coefficients of the regression. For
comparative purposes, this was done even in cases where the
intercept-only model was superior.


So in our case, we have, for each SET:  

+  response variable: pin_height  
+  fixed effect: date  
+  random effects: arm_position, pin_number  (note, these are nested)  


Great resource on linear mixed models:  
https://ourcodingclub.github.io/2017/03/15/mixed-models.html#one  


On partial pooling and groups, from https://stats.stackexchange.com/questions/4700/what-is-the-difference-between-fixed-effect-random-effect-and-mixed-effect-mode :

To motivate the random effects model, ask yourself: why would you partial pool? Probably because you think the little subgroups are part of some bigger group with a common mean effect. The subgroup means can deviate a bit from the big group mean, but not by an arbitrary amount. To formalize that idea, we posit that the deviations follow a distribution, typically Gaussian. That's where the "random" in random effects comes in: we're assuming the deviations of subgroups from a parent follow the distribution of a random variable. Once you have this idea in mind, the mixed-effects model equations follow naturally.  

.....*While many treatments of this topic focus on a narrow definition of "group", the concept is in fact very flexible: it is just a set of observations that share a common property. A group could be composed of multiple observations of a single person, or multiple people in a school, or multiple schools in a district, or multiple varieties of a single kind of fruit, or multiple kinds of vegetable from the same harvest, or multiple harvests of the same kind of vegetable, etc. Any categorical variable can be used as a grouping variable.



In the case of SETs, the arms and individual pins are "the little subgroups" that are part of "some bigger group" of the SET, with a common mean effect. At Grand Bay (and possibly others?), we have 3 SETs together in a marsh zone, so if we wanted to ask about that general area of the marsh, perhaps SET would also become a random effect ("little subgroup") and the marsh zone would be the fixed effect ("bigger group").

Here it goes with models.


```{r calc_lmm}
models2 <- dat %>%
    group_by(reserve, set_id) %>%
    do(mod = lme(pin_height ~ date, data = ., random = ~1|arm_position/pin_number, na.action = na.omit)) 
```

```{r calc_lmm_coef}
modelcoef2 <- tidy(models2, mod, effects = "fixed") %>%
    filter(term == "date") %>%
    mutate(rate_mm.yr = estimate*365.25,
           se_mm.yr = std.error*365.25,
           CIlow_mm.yr = rate_mm.yr - 1.96*se_mm.yr,
           CIhigh_mm.yr = rate_mm.yr + 1.96*se_mm.yr,
           p_value = round(p.value, 4),
           statistic = round(statistic, 3)) %>%
    select(reserve, set_id, rate_mm.yr, se_mm.yr, CIlow_mm.yr, CIhigh_mm.yr, statistic, p_value)

kable(modelcoef2, caption = "lme estimates of change by SET", 
      digits = 3,
      align = 'c')
```

See other diagnostics from the models:  

```{r calc_lmm_other}
kable(glance(models2, mod))
```

***
***


## Graphics from LMM rates  

```{r plot_slr_ci_lmm, fig.width = 7, fig.height = 6}
ggplot() +
    geom_blank(data = modelcoef2, aes(x = set_id, y = rate_mm.yr)) +
    geom_ribbon(aes(x = 0:(nrow(modelcoef2)+1), ymin = slr-slr_ci, ymax = slr+slr_ci), fill = "navyblue", alpha = 0.1) +
    geom_hline(aes(yintercept = slr), col = "navyblue", size = 1, alpha = 0.9) +
    geom_hline(aes(yintercept = 0), col = "gray70") +
    geom_errorbar(data = modelcoef2, aes(x = set_id, ymin = CIlow_mm.yr, ymax = CIhigh_mm.yr), col = "gray55", size = 1) +
    geom_point(data = modelcoef2, aes(x = set_id, y = rate_mm.yr), size = 3, col = "red3") +
    theme_classic() + 
    labs(title = "Elevation Change, 95% Confidence Intervals (LMM)", subtitle = paste0("Local SLR in blue: ", slr, " +/- ", slr_ci, " mm/yr"), x = "SET", y = "Rate of change (mm/yr)") +
    coord_flip()
```


### Cumulative change graph here?  

### NAVD88 graph if we can figure it out  